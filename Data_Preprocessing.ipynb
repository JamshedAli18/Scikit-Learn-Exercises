{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "KAlmC6cNrOqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the Iris dataset.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "# Standardize the Iris dataset\n",
        "scaler = StandardScaler()\n",
        "iris_scaled = scaler.fit_transform(iris.data)\n",
        "iris_scaled_df = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print(iris_scaled_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM47O9J0rWBe",
        "outputId": "ecdd6b97-e2b4-4110-80be-62d56a9fb454"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0          -0.900681          1.019004          -1.340227         -1.315444\n",
            "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
            "2          -1.385353          0.328414          -1.397064         -1.315444\n",
            "3          -1.506521          0.098217          -1.283389         -1.315444\n",
            "4          -1.021849          1.249201          -1.340227         -1.315444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the target variable in the Iris dataset.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target variable\n",
        "encoder = LabelEncoder()\n",
        "iris_target_encoded = encoder.fit_transform(iris.target)\n",
        "print(f'Encoded target variable:\\n{iris_target_encoded}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuWfC5rArtqz",
        "outputId": "12034bc7-814a-48b9-dedf-a700fc8582ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded target variable:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features of the digits dataset.\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "# Normalize the digits dataset\n",
        "normalizer = Normalizer()\n",
        "digits_normalized = normalizer.fit_transform(digits.data)\n",
        "print(f'Normalized digits dataset (first 5 samples):\\n{digits_normalized[:5]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvs9aevvsH--",
        "outputId": "89c667a1-6e79-4191-cbe8-5c5469efecc5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized digits dataset (first 5 samples):\n",
            "[[0.         0.         0.09024036 0.23462493 0.16243265 0.01804807\n",
            "  0.         0.         0.         0.         0.23462493 0.27072108\n",
            "  0.18048072 0.27072108 0.09024036 0.         0.         0.05414422\n",
            "  0.27072108 0.03609614 0.         0.19852879 0.14438458 0.\n",
            "  0.         0.07219229 0.21657686 0.         0.         0.14438458\n",
            "  0.14438458 0.         0.         0.09024036 0.14438458 0.\n",
            "  0.         0.16243265 0.14438458 0.         0.         0.07219229\n",
            "  0.19852879 0.         0.01804807 0.21657686 0.1263365  0.\n",
            "  0.         0.03609614 0.25267301 0.09024036 0.18048072 0.21657686\n",
            "  0.         0.         0.         0.         0.10828843 0.23462493\n",
            "  0.18048072 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.18496595 0.20037978 0.07706915\n",
            "  0.         0.         0.         0.         0.         0.16955212\n",
            "  0.24662126 0.13872446 0.         0.         0.         0.\n",
            "  0.04624149 0.23120744 0.24662126 0.09248297 0.         0.\n",
            "  0.         0.1078968  0.23120744 0.24662126 0.24662126 0.03082766\n",
            "  0.         0.         0.         0.         0.01541383 0.24662126\n",
            "  0.24662126 0.04624149 0.         0.         0.         0.\n",
            "  0.01541383 0.24662126 0.24662126 0.09248297 0.         0.\n",
            "  0.         0.         0.01541383 0.24662126 0.24662126 0.09248297\n",
            "  0.         0.         0.         0.         0.         0.16955212\n",
            "  0.24662126 0.15413829 0.         0.        ]\n",
            " [0.         0.         0.         0.06038467 0.2264425  0.181154\n",
            "  0.         0.         0.         0.         0.0452885  0.24153867\n",
            "  0.2264425  0.21134634 0.         0.         0.         0.\n",
            "  0.12076934 0.19625017 0.12076934 0.24153867 0.         0.\n",
            "  0.         0.         0.01509617 0.090577   0.2264425  0.16605784\n",
            "  0.         0.         0.         0.01509617 0.12076934 0.19625017\n",
            "  0.2264425  0.01509617 0.         0.         0.         0.1358655\n",
            "  0.24153867 0.24153867 0.07548083 0.         0.         0.\n",
            "  0.         0.0452885  0.19625017 0.24153867 0.24153867 0.16605784\n",
            "  0.07548083 0.         0.         0.         0.         0.0452885\n",
            "  0.16605784 0.24153867 0.1358655  0.        ]\n",
            " [0.         0.         0.12881496 0.27603207 0.23922779 0.01840214\n",
            "  0.         0.         0.         0.1472171  0.23922779 0.11041283\n",
            "  0.27603207 0.07360855 0.         0.         0.         0.03680428\n",
            "  0.01840214 0.23922779 0.23922779 0.         0.         0.\n",
            "  0.         0.         0.03680428 0.27603207 0.20242351 0.01840214\n",
            "  0.         0.         0.         0.         0.         0.01840214\n",
            "  0.22082565 0.22082565 0.01840214 0.         0.         0.\n",
            "  0.         0.         0.01840214 0.18402138 0.1472171  0.\n",
            "  0.         0.         0.1472171  0.07360855 0.09201069 0.25762993\n",
            "  0.16561924 0.         0.         0.         0.12881496 0.23922779\n",
            "  0.23922779 0.16561924 0.         0.        ]\n",
            " [0.         0.         0.         0.01803633 0.19839958 0.\n",
            "  0.         0.         0.         0.         0.         0.12625428\n",
            "  0.14429061 0.         0.         0.         0.         0.\n",
            "  0.01803633 0.23447223 0.10821795 0.03607265 0.03607265 0.\n",
            "  0.         0.         0.12625428 0.27054489 0.         0.16232693\n",
            "  0.14429061 0.         0.         0.09018163 0.28858121 0.18036326\n",
            "  0.         0.28858121 0.10821795 0.         0.         0.0721453\n",
            "  0.27054489 0.28858121 0.23447223 0.28858121 0.01803633 0.\n",
            "  0.         0.         0.         0.05410898 0.27054489 0.18036326\n",
            "  0.         0.         0.         0.         0.         0.03607265\n",
            "  0.28858121 0.0721453  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values in a dataset with mean strategy.\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset with missing values\n",
        "data_with_missing_values = np.array([[1, 2, np.nan], [3, np.nan, 6], [7, 8, 9]])\n",
        "\n",
        "# Impute missing values with mean strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputed_data = imputer.fit_transform(data_with_missing_values)\n",
        "print(f'Imputed dataset:\\n{imputed_data}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpqV_An4shB1",
        "outputId": "a526c97c-2821-40d4-f571-e3253371863d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputed dataset:\n",
            "[[1.  2.  7.5]\n",
            " [3.  5.  6. ]\n",
            " [7.  8.  9. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XhX4EyZUsvvZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}